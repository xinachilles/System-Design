# 23



---

Summary

The text discusses the configuration options and considerations for AWS Lambda functions, including permissions, resource-based policies, execution roles, VPC connections, security groups, asynchronous invocations, memory, CPU, and timeout settings.

Facts

- Lambda functions have associated resource-based policies, which can be modified by services like API Gateway.
- Deleting a Lambda function also deletes its policy, which can disrupt services like API Gateway.
- Lambda functions have an execution role that dictates what actions they can perform within AWS.
- If a Lambda function interacts with AWS services like DynamoDB or SQS, the execution role must have the necessary permissions.
- ![Execution role IAM role that Lambda has permissions to assume when you invoke a function. You need to select or create an execution role when you create the function, and you can modify the policies associated with the role via IAM. The default Lambda execution role includes permissions to write to Amazon CloudWatch Logs. As you add additional targets (for example, writing to a database or sending an Amazon Simple Notification Service topic), your Lambda function's execution role needs permissions to interact with those targets. The role needs permissions to write to a database or SNS topic, for example. IAM provides managed policies that you can add to your function to simplify getting the permissions that you need. event source Execution role to read or write to DynamoDB Execution role to poll Amazon a queue Target ](../../../media/AWS-Developing-Serverless-Solutions-on-AWS-Module-7---Lambda-23-image1.png)
- 



- Lambda functions can be connected to a VPC to access resources within that VPC.
- Security groups associated with Lambda functions are crucial for debugging network-related issues.



![Execution role to connect to a VPC Execution role Amazon EPS RDS R D S Execution role Or database credentials To interact with resources that are in a VPC, in addition to execution role permissions to interact with the resource, you need to connect your function to the VPC. Your execution role permissions must include the ability to work with network interfaces. This is because, when you connect a function to a VPC, Lambda creates an elastic network interface for each combination of security group and subnet in your function's VPC configuration. A managed policy includes the permissions that you need. The Lambda console has an option to connect to the VPC. Once that is set up, you can configure an Amazon EFS volume for the function, and you can configure the database proxy feature, which lets you create a pool of connections to an Amazon RDS instance. You won't be able to complete configuration of these options until you have connected the function to the appropriate VPC and subnet. ](../../../media/AWS-Developing-Serverless-Solutions-on-AWS-Module-7---Lambda-23-image2.png)





- Lambda functions can be invoked asynchronously, either from code or using services like Kinesis Data Stream and Amazon S3.
- Results of asynchronous Lambda functions can be directed to destinations like EventBridge, SNS, or SQS using DestinationConfig.
- Failed Lambda invocations can be sent to a dead-letter queue for debugging.
- ![Targeting destinations for stream or async invocations "Desti nati onconfig " : "0nFai1ure' stream Amazon Kinesis Data Streams async Amazon SQS "Desti nati onconfn g "0nSuccess "0nFai lure Dead-letter queue Amazon SNS Amazon EventBridge Amazon SNS Amazon S; SNS topic SQS queue Amazon SQS AWS Lambda ](../../../media/AWS-Developing-Serverless-Solutions-on-AWS-Module-7---Lambda-23-image3.png)
- 



- Configuring a Lambda function includes setting memory and timeout values.
- Memory allocation impacts the CPU available to the function, which can affect performance and costs.
- Increasing memory might reduce the function's execution time, potentially lowering costs.
- Timeouts should be set to prevent prolonged execution of stuck functions, balancing performance and cost.







![Permisssions As you add triggers and targets to your function, you need to manage two key permissions: 1. Permissions to invoke your function, which is dictated in the resource-based policy. 2. Permissions for your Lambda function to interact with other resources through an execution role You need to set up permissions when you create a function. Sources and targets Sources are the services that trigger Lambda synchronously or asynchronously, when you add a trigger to your function with the Lambda console. A target or destination is an AWS resource that receives invocation records for a function. You must give a function permissions to the target through the execution role. Memory and time out The cost of executing a lambda function is dependent on memory and duration. You would want to balance the allocation of these resources in such a way that it optimizes the function's performance. ](../../../media/AWS-Developing-Serverless-Solutions-on-AWS-Module-7---Lambda-23-image4.png)







![Resource-based policy Resource-based policy Synchronous asynchronous event sources Amuar API Gat Amazon SS Target resources Permissions to invoke your function is dictated by the resource-based policy. For services that invoke Lambda synchronously or asynchronously, when you add an event source to your function with the Lambda console, the console updates the function's resource-based policy to allow the service to invoke it. Likewise, if you configure an integration with Lambda from another service console, the permissions to invoke the function are created for you. For example, if you create an API in Amazon API Gateway that targets a Lambda function, permissions to invoke that API are added when you create the API. If you need to grant permissions to other accounts or services that aren't available in the Lambda console, you can use the AWS CLI to update the resource-based policy. You can also use AWS Identity and Access Management (IAM) roles to grant permissions to invoke. The key, as a developer, is that you need to provide permissions from source to function to invoke the function. ](../../../media/AWS-Developing-Serverless-Solutions-on-AWS-Module-7---Lambda-23-image5.png)





























![A destination is an AWS resource that receives invocation records for a function. You must give a function permissions to the destination through the execution role. Streaming event sources can use an OnFailure destination in conjunction with stream error- handling features to move failed records off of the stream and send them to services like Amazon SNS or Amazon SQS for handling offline. Asynchronous records can include both OnSuccess and OnFailure destinations. You can configure services like Amazon EventBridge, Amazon SNS, and Amazon SQS as your OnFailure destination to handle the failed records. As an alternative to an OnFailure destination, you can configure your function with a dead-letter queue to save discarded events for further processing. A dead-letter queue is part of a function's version-specific configuration, so it is locked in when you publish a version. ](../../../media/AWS-Developing-Serverless-Solutions-on-AWS-Module-7---Lambda-23-image6.png)






